{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python\n",
    "# pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load YOLOv8 Model for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate unique colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_color(exist_colors):\n",
    "    while True:\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        if color not in exist_colors and not shade_of_red(color):\n",
    "            return color\n",
    "\n",
    "def shade_of_red(color):\n",
    "    r, g, b = color\n",
    "    return r > 100 and g < 100 and b < 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bounding boxes with unique colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(\n",
    "    \"rtsp://192.168.10.4:8080/h264_ulaw.sdp\"\n",
    ")  # RTSP video stream\n",
    "colors = {}\n",
    "timer_start = False\n",
    "select_id = None\n",
    "timer = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_event(event, x, y, flags, param):\n",
    "    global select_id, timer, colors, timer_start\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for person in people:\n",
    "            bounding_box = person[\"bounding_box\"]\n",
    "            id = person[\"id\"]\n",
    "            if (\n",
    "                bounding_box[0] < x < bounding_box[2]\n",
    "                and bounding_box[1] < y < bounding_box[3]\n",
    "            ):\n",
    "                if select_id is not None:\n",
    "                    colors[select_id] = unique_color(colors.values())\n",
    "                select_id = id\n",
    "                timer = 0\n",
    "                timer_start = False\n",
    "                break\n",
    "\n",
    "\n",
    "cv2.namedWindow(\"Object_detection\")\n",
    "cv2.setMouseCallback(\"Object_detection\", click_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Reads a frame from the video stream\n",
    "    return_val, frame = capture.read()\n",
    "    if not return_val:\n",
    "        break\n",
    "\n",
    "    # Object Detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Processing Detections\n",
    "    people = []\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            cls = detection.cls.cpu().numpy()\n",
    "            if cls == 0:  # Class 0 is usually \"person\" in Common objects dataset\n",
    "                bounding_box = detection.xyxy.cpu().numpy()[0]\n",
    "                people.append({\"bounding_box\": bounding_box, \"id\": len(people)})\n",
    "\n",
    "    # Drawing Bounding Boxes\n",
    "    for person in people:\n",
    "        bounding_box = person[\"bounding_box\"]\n",
    "        id = person[\"id\"]\n",
    "        if id not in colors:\n",
    "            colors[id] = unique_color(colors.values())\n",
    "\n",
    "        color = colors[id]\n",
    "        if id == select_id:\n",
    "            color = (0, 0, 255)  # Red color for the selected bounding box\n",
    "            timer_start = True\n",
    "\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (int(bounding_box[0]), int(bounding_box[1])),\n",
    "            (int(bounding_box[2]), int(bounding_box[3])),\n",
    "            color,\n",
    "            2,\n",
    "        )\n",
    "        if id == select_id and timer_start:\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Timer: {timer}s\",\n",
    "                (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1,\n",
    "                (0, 0, 255),\n",
    "                2,\n",
    "                cv2.LINE_AA,\n",
    "            )\n",
    "\n",
    "    # Displaying Frame\n",
    "    cv2.imshow(\"Object_detection\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord(\"q\"):  #  press'q' key to exit the loop.\n",
    "        break\n",
    "\n",
    "    if timer_start:\n",
    "        timer += 1\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-object_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
